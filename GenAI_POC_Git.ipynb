{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "pTu1O47m9hwL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dqx4bhKuUYpi"
      },
      "outputs": [],
      "source": [
        "# Need this to get access to models/data\n",
        "# make sure to use gpu runtime\n",
        "!pip install huggingface_hub\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n",
        "# Unsloth models make inference and training fast by using 4 bit models. Check the git location for updates.\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps \"xformers<0.0.26\" trl peft accelerate bitsandbytes"
      ],
      "metadata": {
        "id": "5jYMbV4Z-v_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "# whenever you pip install, you must restart the runtime to update the gpu with the installs"
      ],
      "metadata": {
        "id": "0k0_y0jUARyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unsloth\n",
        "!pip install wandb"
      ],
      "metadata": {
        "id": "mrK1v7gs_qkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login() #weights and biases - create account and get api to track training metrics"
      ],
      "metadata": {
        "id": "oOqQgLD7BCQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyIHBjhcQcsQ"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-8U1laBQgRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaac84fa-5ce8-44c5-e9cb-c597ec3e0c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# adding google drive access to save files and models. packages, training models, and creating data takes disk space\n",
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "colab_path = '/content/notebooks'\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', colab_path)\n",
        "sys.path.insert(0,colab_path)\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYCRSn00ybeq"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWxnRPTRycMO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import imaplib\n",
        "import email\n",
        "from email.header import decode_header\n",
        "\n",
        "# Set up the IMAP server connection\n",
        "# enter your own Gmail credentials\n",
        "imap_server = 'imap.gmail.com'\n",
        "port = 993\n",
        "username = @gmail.com\n",
        "password = # this isn't your normal password, you need gmail app password. you can google for instructions\n",
        "\n",
        "# Create an IMAP4_SSL connection\n",
        "connection = imaplib.IMAP4_SSL(imap_server, port)\n",
        "\n",
        "# Login to the server\n",
        "connection.login(username, password)\n",
        "\n",
        "# Select the inbox folder\n",
        "connection.select('Inbox')\n",
        "\n",
        "# Search for emails from Banana Republic Factory\n",
        "result, data = connection.search(None, '(FROM \"bananarepublicfactory.com\" SUBJECT \"% off\")')\n",
        "\n",
        "# Fetch the email subject lines\n",
        "subject_lines = []\n",
        "for num in data[0].split():\n",
        "    result, data = connection.fetch(num, '(BODY[HEADER.FIELDS (SUBJECT)])')\n",
        "    raw_subject = str(data[0][1])\n",
        "    raw_subject = raw_subject.split(\"?\", 1)[0]\n",
        "    raw_subject = raw_subject.split('\\\\', 1)[0]\n",
        "    raw_subject = raw_subject.split(\"=\", 1)[0]\n",
        "    if isinstance(raw_subject, str):\n",
        "        print(raw_subject)\n",
        "        subject, encoding = decode_header(raw_subject)[0]\n",
        "        subject = subject\n",
        "        print(subject)\n",
        "    else:\n",
        "         print(raw_subject)\n",
        "    # if subject is not None:\n",
        "    #     print(subject)\n",
        "    #     subject = subject.lower()\n",
        "    if '' in subject  in subject:\n",
        "        subject_lines.append(subject)\n",
        "\n",
        "# Limit the number of subject lines to 10000\n",
        "subject_lines = subject_lines[:1000]\n",
        "\n",
        "# Create a DataFrame with the subject lines\n",
        "df = pd.DataFrame({'subject_line': subject_lines})\n",
        "\n",
        "# Close the connection\n",
        "connection.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBMmwLS5wrNf"
      },
      "outputs": [],
      "source": [
        "df1 = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H88W2SwA3DYr"
      },
      "outputs": [],
      "source": [
        "df1['subject_line'] = df1['subject_line'].str.replace('b\"Subject: ', \"\").dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_Q5vrmY3V7C"
      },
      "outputs": [],
      "source": [
        "df1 = df1[df1['subject_line'].str.len() > 0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulL4Jd3xin3w"
      },
      "outputs": [],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb-elTkQ7Adf"
      },
      "outputs": [],
      "source": [
        "# use this cell if you are running the gmail subject line collection multiple times\n",
        "dfp = pd.concat([df2,df3,df4, df5], ignore_index=True) #"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfp = df1.drop_duplicates(subset='subject_line', keep='first')\n",
        "dfp['subject_line'].count()"
      ],
      "metadata": {
        "id": "MyvCwcDudjg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfecI8CTa3D2"
      },
      "outputs": [],
      "source": [
        "dfp.to_csv('/content/drive/MyDrive/Colab Notebooks/subject_lines.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "204rLpVI_ydI"
      },
      "source": [
        "## Training data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Turning the collected subject lines into training data by collecting labels and assigning what the data, prompt, and label will be."
      ],
      "metadata": {
        "id": "V-Y-M7Q--fGF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3HlA5Q2qYIL"
      },
      "outputs": [],
      "source": [
        "# uncomment line below to remove model and tokenizer and start over fresh without disconnecting runtime\n",
        "# del model, tokenizer\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 1024 !\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "if True:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"unsloth/llama-3-8b-bnb-4bit\", # check on all the models that are compatible. many models work with unsloth\n",
        "        max_seq_length = max_seq_length,\n",
        "        device_map = \"auto\",\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "        cache_dir='/content/gdrive/MyDrive/model_cache/',\n",
        "        max_length = 2048\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving models to preserve original model and tokenizer to compare results after tuning\n",
        "model_orig=model\n",
        "tokenizer_orig=tokenizer"
      ],
      "metadata": {
        "id": "1SmztkpBgU2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf1ES3AO67_6"
      },
      "outputs": [],
      "source": [
        "# this is to access the app folder.\n",
        "os.sys.path.append('/usr/local/lib/python3.10/dist-packages')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgUz6wPZGO38"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import json\n",
        "\n",
        "data = [{\"role\": \"system\", \"content\": \"you are a email marketing bot that can read an email subject line and provide the purpose, season, product, and promotion amount in a concise matter.\"}]\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/subject_lines.csv', 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader)  # Skip the header row\n",
        "    for row in reader:\n",
        "        subject_line = row[1]\n",
        "        data.append({\"role\": \"user\", \"content\": subject_line})\n",
        "\n",
        "with open('all_prompts.json', 'w') as outfile:\n",
        "    json.dump(data, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay6gVQZcKFhG"
      },
      "outputs": [],
      "source": [
        "\n",
        "import transformers\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "import pandas as pd\n",
        "import jinja2\n",
        "\n",
        "\n",
        "alpaca_prompt = \"\"\"\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPCI5LYpZtQC"
      },
      "outputs": [],
      "source": [
        "# Load the JSON file\n",
        "df = pd.DataFrame()\n",
        "\n",
        "with open('all_prompts.json', 'r') as file:\n",
        "    messages = json.load(file)\n",
        "\n",
        "for message in messages:\n",
        "    # Get the content from the message\n",
        "    content = message['content']\n",
        "\n",
        "    # Tokenize the prompt and get the response from the LLaMA model\n",
        "    mna_news_instruction = \"\"\"what is the purpose, season, product, of this email subject line? provide an answer with less than 25 words:\n",
        "                              Responde in this format: purpose: {purpose}, season: {season}, product: {product}, promotion amount: {amount}\"\"\"\n",
        "    mna_news_input = content\n",
        "    alpaca_prompt.format(mna_news_instruction, mna_news_input, \"\")\n",
        "    inputs = tokenizer([alpaca_prompt.format(mna_news_instruction, mna_news_input, \"\")], return_tensors = \"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens = 64)\n",
        "    response = tokenizer.batch_decode(outputs)[0]\n",
        "    print(response)\n",
        "    # response = print(response_samp).split(\"### Response:\")[1]\n",
        "    # Add the content and response to the DataFrame\n",
        "    df = pd.concat([df, pd.DataFrame({'content': content, 'response': response}, index=[0])], ignore_index=True)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('content_response.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g8gGlE0gO7x"
      },
      "source": [
        "#### turn new csv into correct format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_UQAmbpw5BV"
      },
      "outputs": [],
      "source": [
        "\n",
        "!cp all_prompts.json \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "!cp content_response.csv \"/content/drive/MyDrive/Colab Notebooks\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Display the dataframe\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "gMSB4jK0etuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y2mfFRZFa7f"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read in the content_response.csv file\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/content_response.csv')\n",
        "df.head()\n",
        "# clean up responses\n",
        "df = df.iloc[1:]\n",
        "df['response'] = df['response'].str.split('### Response:').str[1]\n",
        "df['response'] = df['response'].str.replace('\\n', '')\n",
        "df['response'] = df['response'].str.replace(')', '')\n",
        "df['response'] = df['response'].str.replace('(', '')\n",
        "df['response'] = df['response'].str.split('###').str[0]\n",
        "df['response'] = df['response'].str.split('<').str[0]\n",
        "# Keep only the content and response columns\n",
        "df = df[['content', 'response']]\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final clean up to remove responses that are same as input\n",
        "\n",
        "df = df[~(df.apply(lambda row: row['content'].replace(' ', '')[:25] == row['response'].replace(' ', '')[:25], axis=1))]"
      ],
      "metadata": {
        "id": "mYBQ45P_8923"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "id": "73AJ-8fu9ABG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Keep only the content and response columns\n",
        "df = df[['content', 'response']]\n",
        "\n",
        "# Add a new column named \"instruction\"\n",
        "df['instruction'] = \"Generate a marketing subject line specifically for my purpose\"\n",
        "\n",
        "# Rename the columns\n",
        "df.rename(columns={'content': 'output', 'response': 'input'}, inplace=True)\n",
        "\n",
        "# Rearrange the columns\n",
        "df = df[['instruction', 'input', 'output']]\n",
        "\n",
        "# Store the DataFrame into a new CSV file\n",
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/training_data_sl.csv', index=False)\n"
      ],
      "metadata": {
        "id": "PwXNJ9RekIfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import json\n",
        "\n",
        "# Open the CSV file\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/training_data_sl.csv', 'r') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "\n",
        "    # Convert the CSV data to a list of dictionaries\n",
        "    data = [row for row in reader]\n",
        "\n",
        "# Write the data to a JSON file\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/training_data_sl.json', 'w') as jsonfile:\n",
        "    json.dump(data, jsonfile, indent=4)"
      ],
      "metadata": {
        "id": "2XD_OlE5nyNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVLVAG1yot7g"
      },
      "source": [
        "## Fine tune LLM with LoRa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "colab_path = '/content/notebooks'\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', colab_path)\n",
        "sys.path.insert(0,colab_path)\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "metadata": {
        "id": "_tt7dQX_0krN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# del model, tokenizer\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 1024 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "if True:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"unsloth/llama-3-8b-bnb-4bit\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        device_map = \"auto\",\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "        cache_dir='/content/gdrive/MyDrive/model_cache/',\n",
        "        max_length = 2048\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n"
      ],
      "metadata": {
        "id": "a14Oarnco3G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjY75GoYUCB8"
      },
      "outputs": [],
      "source": [
        "alpaca_prompt = \"\"\"\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"jeffsan730/email_subject_line\", split = \"train\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "# Load the dataset\n",
        "dataset = load_dataset('jeffsan730/email_subject_line',split='train')\n",
        "dataset=dataset.map(formatting_prompts_func, batched = True,)\n",
        "# Split the dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "train_dataset = Dataset.from_dict(train_dataset)\n",
        "test_dataset = Dataset.from_dict(test_dataset)"
      ],
      "metadata": {
        "id": "Hw8-7qJcLowD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "19EyMKNzPDLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=model_orig\n",
        "tokenizer=tokenizer_orig"
      ],
      "metadata": {
        "id": "mxgmNP13hbni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 8, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 32,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = True,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ],
      "metadata": {
        "id": "nj_B0KsA1rLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vl1jOKBchaY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "# del trainer\n",
        "args = TrainingArguments(\n",
        "        per_device_train_batch_size = 10,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 100,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "    )\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = test_dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        per_device_eval_batch_size = 2,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 100,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to=\"wandb\",  # enable logging to W&B\n",
        "        run_name=\"batch_size_2_max_steps100\",  # name of the W&B run (optional)\n",
        "        logging_steps=1,  # how often to log to W&B\n",
        "        logging_strategy = 'steps',\n",
        "        save_total_limit=2,\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "trdTi66M2NsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env WANDB_WATCH=all\n",
        "%env WANDB_SILENT=true"
      ],
      "metadata": {
        "id": "PzeBdyRaXcG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from transformers.utils import logging\n",
        "import wandb\n",
        "\n",
        "logging.set_verbosity_info()\n",
        "project_name = \"genai-poc\"\n",
        "entity = \"wandb\"\n",
        "# os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
        "\n",
        "wandb.init(project=project_name, name = \"llama3-8b-email_sl\")"
      ],
      "metadata": {
        "id": "lNDBXPQ2XpgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = args"
      ],
      "metadata": {
        "id": "er-W_X2xYCAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ],
      "metadata": {
        "id": "JRsqtdxS2YC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()\n",
        "evaluation_stats = trainer.evaluate()\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "TgmSKB5-2bu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bAm7w0vXmjwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###@title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ],
      "metadata": {
        "id": "ijMRdH8v2eEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "code to generate multiple outputs"
      ],
      "metadata": {
        "id": "yJ-q6zxmWMdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "appended_output = []\n",
        "\n",
        "for _ in range(5):\n",
        "    inputs = tokenizer(\n",
        "        [\n",
        "            alpaca_prompt.format(\n",
        "                \"Generate marketing subject lines specifically for my purpose\",\n",
        "                \"\"\"purpose: Early Access, season: Black Friday, product: Tablets, promotion amount: Up to 70% OFF!   \"\"\",\n",
        "                \"\",\n",
        "            )\n",
        "        ], return_tensors=\"pt\"\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(**inputs, max_new_tokens=1028, use_cache=False, do_sample=True)\n",
        "    output = tokenizer.batch_decode(outputs)[0]\n",
        "    appended_output.append(output)\n",
        "\n",
        "print(appended_output)"
      ],
      "metadata": {
        "id": "zqGPzJW82kpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.sub(r'### Instruction:.*### Response:', '### Response:', str('\\n'.join(appended_output)), flags=re.DOTALL)"
      ],
      "metadata": {
        "id": "5TqJGfKDEOnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output2=str((appended_output)).replace(\"'\", \"\")\n",
        "output2=re.sub(r'\\n', ' ', output2)\n",
        "print(output2)"
      ],
      "metadata": {
        "id": "CCzdmkTx-A1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match = re.search(r'### Response:(.*?)&&&', output2)\n",
        "if match:\n",
        "    print(\"Response: \" + match.group(1).strip())"
      ],
      "metadata": {
        "id": "bs_20hJM_gxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(match)"
      ],
      "metadata": {
        "id": "r-IhACVSAFN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"Generate marketing subject lines specifically for my purpose\",\n",
        "        \"\"\"purpose: Sale, season: Labor Day, product: AI Appliances, promotion amount: Up to 50% OFF!   \"\"\",\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1028, use_cache = False, num_return_sequences = 5)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "id": "H-BlT1-x370E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('/content/drive/MyDrive/Colab Notebooks/subjectline_model_unslothllama8b')\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/Colab Notebooks/subjectline_model_unslothllama8b')"
      ],
      "metadata": {
        "id": "H68oRMfXobsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Assuming your model and tokenizer are stored in the variables \"model\" and \"tokenizer\"\n",
        "\n",
        "# Define the model architecture and tokenizer type\n",
        "model_architecture = \"llama\"\n",
        "tokenizer_type = \"LLaMATokenizer\"\n",
        "\n",
        "# Save the model and tokenizer to the directory\n",
        "model.save_pretrained(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/subjectline_model_unslothllama8b',\n",
        "    model_architecture=model_architecture,\n",
        "    tokenizer_type=tokenizer_type\n",
        ")\n",
        "\n",
        "tokenizer.save_pretrained(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/subjectline_model_unslothllama8b',\n",
        "    tokenizer_type=tokenizer_type\n",
        ")"
      ],
      "metadata": {
        "id": "7_U3fcsuL8Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "id": "ZsuHF2QDIl1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/gdrive\""
      ],
      "metadata": {
        "id": "7AawpQPHo0WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(tokenizer))"
      ],
      "metadata": {
        "id": "2xidETPmudaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(tokenizer))"
      ],
      "metadata": {
        "id": "rKevWGeK0Y40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!mv \"/content/drive/MyDrive/Colab Notebooks/lora_model\" \"/content/drive/MyDrive/h2ogpt\"\n"
      ],
      "metadata": {
        "id": "I-LHwths079z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Original Model output"
      ],
      "metadata": {
        "id": "Q6geCW0PwrqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"Generate a marketing subject line specifically for my purpose\", # instruction\n",
        "        \"\"\"The purpose of this email subject line is to inform the customer that the sale has started\n",
        "        and that they can get 60% off everything. The season is the holiday season, and the product all producst are on sale.\n",
        "        The subject line should be short and to the point, and be clear that the customer can get a discount on everything\n",
        "        in the store.\"\"\",\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1028, use_cache = False)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "id": "-d19FFo93bJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"Generate a marketing subject line specifically for my purpose\", # instruction\n",
        "        \"\"\"The purpose of this email subject line is to inform the customer that the sale has started\n",
        "        and that they can get 60% off denim jeans. The season is the fall sean, and the only jeans are on sale.\n",
        "        The subject line should be short and to the point, be clear, and create urgency.\n",
        "        \"\"\",\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1028, use_cache = False)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "id": "6POkQNO8wwai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = {\n",
        "    \"Product\": [\"All/No specific product\", \"denim jeans\", \"outerwear\", \"shoes\", \"sunglasses\", \"shirts\"],\n",
        "    \"Season\": [\"Summer\", \"Winter\", \"Spring\", \"Fall\"],\n",
        "    \"Purpose\": [\"Fashion accessory\", \"Gift\", \"Everyday use\"]\n",
        "}\n",
        "\n",
        "output = model.generate(input_ids=input_ids, format=template, keywords=keywords)"
      ],
      "metadata": {
        "id": "tEwU7CxlwzTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Local Agentic RAG\n",
        "\n",
        "\n",
        "1.   One way to create agentic system and reduce errors\n",
        "2.   Uses LangGraph - many resources online\n",
        "\n"
      ],
      "metadata": {
        "id": "oJMh5Hu_hAq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Routing: Adaptive RAG ( [paper](https://arxiv.org/abs/2403.14403)). Route questions to different retrieval approaches\n",
        "*   Fallback: Corrective RAG [paper](https://arxiv.org/pdf/2401.15884.pdf). Fallback to web search if docs are not relevant to query\n",
        "*   Self-correction: Self-RAG [paper](https://arxiv.org/abs/2310.11511). Fix answers w/ hallucinations or don’t address question\n",
        "\n"
      ],
      "metadata": {
        "id": "-OXIb5hfoGuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-nomic langchain_community tiktoken langchainhub chromadb langchain langgraph tavily-python gpt4all fastembed langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK8gElbNNOQi",
        "outputId": "e3a1d627-a954-42b2-c2c6-9733293b2244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-nomic\n",
            "  Downloading langchain_nomic-0.1.0-py3-none-any.whl (3.4 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchainhub\n",
            "  Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.0-py3-none-any.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.2.0-py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langgraph\n",
            "  Downloading langgraph-0.0.50-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.3/83.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tavily-python\n",
            "  Downloading tavily_python-0.3.3-py3-none-any.whl (5.4 kB)\n",
            "Collecting gpt4all\n",
            "  Downloading gpt4all-2.6.0-py3-none-manylinux1_x86_64.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastembed\n",
            "  Downloading fastembed-0.2.7-py3-none-any.whl (27 kB)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.1.4-py3-none-any.whl (11 kB)\n",
            "Collecting langchain-core<0.3,>=0.1.46 (from langchain-nomic)\n",
            "  Downloading langchain_core-0.2.0-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.9/307.9 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nomic<4.0.0,>=3.0.12 (from langchain-nomic)\n",
            "  Downloading nomic-3.0.28.tar.gz (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n",
            "  Downloading langsmith-0.1.59-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.2/121.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.7.1)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.11.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.4)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.63.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
            "Collecting uuid6<2025.0.0,>=2024.1.12 (from langgraph)\n",
            "  Downloading uuid6-2024.1.12-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: huggingface-hub<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from fastembed) (0.20.3)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings"
      ],
      "metadata": {
        "id": "_-B2forfN46U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "c3f9ead9-06cf-46a2-e06a-5c505b6ea89b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-540d29dac615>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_splitter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecursiveCharacterTextSplitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_loaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWebBaseLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChroma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfastembed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastEmbedEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = FastEmbedEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")"
      ],
      "metadata": {
        "id": "q532b2kVN8nG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "\n",
        "llm = ChatGroq(temperature=0,\n",
        "                      model_name=\"Llama3-8b-8192\",\n",
        "                      api_key=userdata.get(\"GROQ_API_KEY\"),)"
      ],
      "metadata": {
        "id": "a9ldkZ6MOEf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "urls = [\n",
        "    \"https://www.omnisend.com/blog/best-email-subject-lines/\",\n",
        "    \"https://www.omnisend.com/blog/product-launch-email/\",\n",
        "    \"https://fluentcrm.com/product-launch-email-subject-lines/\",\n",
        "    \"https://www.localdigital.com.au/blog/28-best-email-subject-lines-that-boost-open-rates\",\n",
        "    \"https://www.klientboost.com/email/email-subject-lines/\"\n",
        "\n",
        "]\n",
        "\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "print(f\"len of documents :{len(docs_list)}\")"
      ],
      "metadata": {
        "id": "gIhuBMcxkSpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2af487-481c-487f-93f2-7b4582003412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len of documents :5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=512, chunk_overlap=0\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "print(f\"length of document chunks generated :{len(doc_splits)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joO-_l_2jZTV",
        "outputId": "cd3ae6a8-1c3a-44bd-dda8-6deb034137ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of document chunks generated :32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(documents=doc_splits,\n",
        "                                    embedding=embed_model,\n",
        "                                    collection_name=\"local-rag\")"
      ],
      "metadata": {
        "id": "k8MUQWMuOxQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate the retriever\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\":2})"
      ],
      "metadata": {
        "id": "UfoZdvfHO6Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implement the Router\n",
        "import time\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an expert at routing a\n",
        "    user question to a vectorstore or web search. Use the vectorstore for questions on email subject lines for\n",
        "    product launches, seasonal sales, specific product sales, and event sales. You do not need to be stringent with the keywords\n",
        "    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search'\n",
        "    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and\n",
        "    no premable or explaination. Question to route: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
        "    input_variables=[\"question\"],\n",
        ")\n",
        "start = time.time()\n",
        "question_router = prompt | llm | JsonOutputParser()\n",
        "#\n",
        "question = \"create email subject line for holiday season, product is tablet, 50% off is the discount\"\n",
        "print(question_router.invoke({\"question\": question}))\n",
        "end = time.time()\n",
        "print(f\"The time required to generate response by Router Chain in seconds:{end - start}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e95NhCDO9lM",
        "outputId": "6ecc8ee9-ea94-48b1-ad3a-7d3e5a0a3890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'datasource': 'vectorstore'}\n",
            "The time required to generate response by Router Chain in seconds:0.33595848083496094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Implement the Generate Chain\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for creating email subject lines for marketing campaigns.\n",
        "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\n",
        "    Use best practices for subject lines and keep the answer concise <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "    Question: {question}\n",
        "    Context: {context}\n",
        "    Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
        "    input_variables=[\"question\", \"document\"],\n",
        ")\n",
        "\n",
        "# Post-processing\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# Chain\n",
        "start = time.time()\n",
        "rag_chain = prompt | llm | StrOutputParser()\n",
        "docs = retriever.invoke(question)\n",
        "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "print(generation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4Wa-zaNPnT3",
        "outputId": "2a9971fc-a315-4381-db08-6c7a665852b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are a few subject line options for a holiday season promotion with a 50% off discount on a tablet:\n",
            "\n",
            "* \"Holiday Gift Alert: 50% Off Our Best-Selling Tablet!\"\n",
            "* \"Deck the Halls with Savings: 50% Off Our Tablet\"\n",
            "* \"Give the Gift of Tech: 50% Off Our Tablet\"\n",
            "* \"Holiday Cheer: 50% Off Our Top-Rated Tablet\"\n",
            "* \"Unwrap the Savings: 50% Off Our Tablet\"\n",
            "\n",
            "These subject lines aim to create a sense of urgency and excitement around the holiday season, while also highlighting the significant discount being offered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieval Grader\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance\n",
        "    of documents to a user's question. If the documents contains keywords related to the user's question,\n",
        "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous results. \\n\n",
        "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
        "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\n",
        "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
        "    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "    \"\"\",\n",
        "    input_variables=[\"question\", \"document\"],\n",
        ")\n",
        "start = time.time()\n",
        "retrieval_grader = prompt | llm | JsonOutputParser()\n",
        "\n",
        "docs = retriever.invoke(question)\n",
        "doc_txt = docs[1].page_content\n",
        "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))\n",
        "end = time.time()\n",
        "print(f\"The time required to generate response by the retrieval grader in seconds:{end - start}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-AwQXfGQUJr",
        "outputId": "20e8613c-e36d-42bd-d156-108f1c58b0cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 'yes'}\n",
            "The time required to generate response by the retrieval grader in seconds:0.7381274700164795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hallucination grader\n",
        "# Prompt\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\" <|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether\n",
        "    the response subject lines are grounded in the documents. Give a binary 'yes' or 'no' score to indicate\n",
        "    whether the response subject lines are grounded in the documents. Provide the binary score as a JSON with a\n",
        "    single key 'score' and no preamble or explanation. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "    Here are the facts:\n",
        "    \\n ------- \\n\n",
        "    {documents}\n",
        "    \\n ------- \\n\n",
        "    Here is the subject lines: {generation}  <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
        "    input_variables=[\"generation\", \"documents\"],\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "hallucination_grader = prompt | llm | JsonOutputParser()\n",
        "hallucination_grader_response = hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})\n",
        "end = time.time()\n",
        "print(f\"The time required to generate response by the generation chain in seconds:{end - start}\")\n",
        "print(hallucination_grader_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La0zUrnqQldX",
        "outputId": "7388e96b-a0ae-4ec4-afda-d2fe608f4302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The time required to generate response by the generation chain in seconds:273.652304649353\n",
            "{'score': 'yes'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#answer grader\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an\n",
        "    answer contains effective subject lines. Give a binary score 'yes' or 'no' to indicate whether the answer is\n",
        "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
        "     <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the answer:\n",
        "    \\n ------- \\n\n",
        "    {generation}\n",
        "    \\n ------- \\n\n",
        "    Here is the question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
        "    input_variables=[\"generation\", \"question\"],\n",
        ")\n",
        "start = time.time()\n",
        "answer_grader = prompt | llm | JsonOutputParser()\n",
        "answer_grader_response = answer_grader.invoke({\"question\": question,\"generation\": generation})\n",
        "end = time.time()\n",
        "print(f\"The time required to generate response by the answer grader in seconds:{end - start}\")\n",
        "print(answer_grader_response)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUplYUHQQ0Ya",
        "outputId": "6021670b-f650-4666-9e3f-54562003f29e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The time required to generate response by the answer grader in seconds:0.45705437660217285\n",
            "{'score': 'yes'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "os.environ['TAVILY_API_KEY'] = \"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\"\n",
        "web_search_tool = TavilySearchResults(k=3)"
      ],
      "metadata": {
        "id": "RBZWn2zAUNoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### State\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    question : str\n",
        "    generation : str\n",
        "    web_search : str\n",
        "    documents : List[str]"
      ],
      "metadata": {
        "id": "2dAzQthJa_Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "def retrieve(state):\n",
        "    \"\"\"\n",
        "    Retrieve documents from vectorstore\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, documents, that contains retrieved documents\n",
        "    \"\"\"\n",
        "    print(\"---RETRIEVE---\")\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    # Retrieval\n",
        "    documents = retriever.invoke(question)\n",
        "    return {\"documents\": documents, \"question\": question}\n",
        "#\n",
        "def generate(state):\n",
        "    \"\"\"\n",
        "    Generate answer using RAG on retrieved documents\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, generation, that contains LLM generation\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # RAG generation\n",
        "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
        "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
        "#\n",
        "def grade_documents(state):\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question\n",
        "    If any document is not relevant, we will set a flag to run web search\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Filtered out irrelevant documents and updated web_search state\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Score each doc\n",
        "    filtered_docs = []\n",
        "    web_search = \"No\"\n",
        "    for d in documents:\n",
        "        score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
        "        grade = score['score']\n",
        "        # Document relevant\n",
        "        if grade.lower() == \"yes\":\n",
        "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
        "            filtered_docs.append(d)\n",
        "        # Document not relevant\n",
        "        else:\n",
        "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
        "            # We do not include the document in filtered_docs\n",
        "            # We set a flag to indicate that we want to run web search\n",
        "            web_search = \"Yes\"\n",
        "            continue\n",
        "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
        "#\n",
        "def web_search(state):\n",
        "    \"\"\"\n",
        "    Web search based based on the question\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Appended web results to documents\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---WEB SEARCH---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Web search\n",
        "    docs = web_search_tool.invoke({\"query\": question})\n",
        "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
        "    web_results = Document(page_content=web_results)\n",
        "    if documents is not None:\n",
        "        documents.append(web_results)\n",
        "    else:\n",
        "        documents = [web_results]\n",
        "    return {\"documents\": documents, \"question\": question}\n",
        "#"
      ],
      "metadata": {
        "id": "rYw9eqjCcPsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_question(state):\n",
        "    \"\"\"\n",
        "    Route question to web search or RAG.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---ROUTE QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    print(question)\n",
        "    source = question_router.invoke({\"question\": question})\n",
        "    print(source)\n",
        "    print(source['datasource'])\n",
        "    if source['datasource'] == 'web_search':\n",
        "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
        "        return \"websearch\"\n",
        "    elif source['datasource'] == 'vectorstore':\n",
        "        print(\"---ROUTE QUESTION TO RAG---\")\n",
        "        return \"vectorstore\""
      ],
      "metadata": {
        "id": "0V6K0MYTcUzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decide_to_generate(state):\n",
        "    \"\"\"\n",
        "    Determines whether to generate an answer, or add web search\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Binary decision for next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
        "    question = state[\"question\"]\n",
        "    web_search = state[\"web_search\"]\n",
        "    filtered_documents = state[\"documents\"]\n",
        "\n",
        "    if web_search == \"Yes\":\n",
        "        # All documents have been filtered check_relevance\n",
        "        # We will re-generate a new query\n",
        "        print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\")\n",
        "        return \"websearch\"\n",
        "    else:\n",
        "        # We have relevant documents, so generate answer\n",
        "        print(\"---DECISION: GENERATE---\")\n",
        "        return \"generate\""
      ],
      "metadata": {
        "id": "AgBPMJQYcYwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grade_generation_v_documents_and_question(state):\n",
        "    \"\"\"\n",
        "    Determines whether the generation is grounded in the document and answers question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Decision for next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECK HALLUCINATIONS---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    generation = state[\"generation\"]\n",
        "\n",
        "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
        "    grade = score['score']\n",
        "\n",
        "    # Check hallucination\n",
        "    if grade == \"yes\":\n",
        "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
        "        # Check question-answering\n",
        "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
        "        score = answer_grader.invoke({\"question\": question,\"generation\": generation})\n",
        "        grade = score['score']\n",
        "        if grade == \"yes\":\n",
        "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
        "            return \"useful\"\n",
        "        else:\n",
        "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
        "            return \"not useful\"\n",
        "    else:\n",
        "        print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
        "        return \"not supported\""
      ],
      "metadata": {
        "id": "2hj7CLbScbv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Define the nodes\n",
        "workflow.add_node(\"websearch\", web_search) # web search\n",
        "workflow.add_node(\"retrieve\", retrieve) # retrieve\n",
        "workflow.add_node(\"grade_documents\", grade_documents) # grade documents\n",
        "workflow.add_node(\"generate\", generate) # generatae"
      ],
      "metadata": {
        "id": "B4IRTZAVces7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.set_conditional_entry_point(\n",
        "    route_question,\n",
        "    {\n",
        "        \"websearch\": \"websearch\",\n",
        "        \"vectorstore\": \"retrieve\",\n",
        "    },\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"grade_documents\",\n",
        "    decide_to_generate,\n",
        "    {\n",
        "        \"websearch\": \"websearch\",\n",
        "        \"generate\": \"generate\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"websearch\", \"generate\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"generate\",\n",
        "    grade_generation_v_documents_and_question,\n",
        "    {\n",
        "        \"not supported\": \"generate\",\n",
        "        \"useful\": END,\n",
        "        \"not useful\": \"websearch\",\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "p9-7keCbcipA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "jg2R65tYclEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = workflow.compile()\n",
        "from pprint import pprint\n",
        "inputs = {\"question\": \"provide 5 good subject lines for a wedding.\"}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        pprint(f\"Finished running: {key}:\")\n",
        "pprint(value[\"generation\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN9d9dTIcm7l",
        "outputId": "7737eac1-d67c-4030-9691-5db5fffdeab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---ROUTE QUESTION---\n",
            "provide 5 good subject lines for a wedding.\n",
            "{'datasource': 'vectorstore'}\n",
            "vectorstore\n",
            "---ROUTE QUESTION TO RAG---\n",
            "---RETRIEVE---\n",
            "'Finished running: retrieve:'\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
            "'Finished running: grade_documents:'\n",
            "---WEB SEARCH---\n",
            "'Finished running: websearch:'\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "'Finished running: generate:'\n",
            "('Here are five good subject line options for a wedding:\\n'\n",
            " '\\n'\n",
            " '1. \"Join Us: [Bride\\'s Name] & [Groom\\'s Name] Say \\'I Do!\\'\"\\n'\n",
            " '2. \"You\\'re Invited: [Bride\\'s Name] & [Groom\\'s Name]\\'s Special Day\"\\n'\n",
            " '3. \"The Countdown Begins: [Bride\\'s Name] & [Groom\\'s Name]\\'s Wedding '\n",
            " 'Details Inside\"\\n'\n",
            " '4. \"Get Ready to Celebrate: [Bride\\'s Name] & [Groom\\'s Name]\\'s Big Day\"\\n'\n",
            " '5. \"Save the Date: [Bride\\'s Name] & [Groom\\'s Name]\\'s Wedding '\n",
            " 'Celebration\"\\n'\n",
            " '\\n'\n",
            " 'These subject lines aim to create a sense of excitement and importance, '\n",
            " 'while also providing a clear idea of the content inside the email.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = workflow.compile()\n",
        "\n",
        "from pprint import pprint\n",
        "inputs = {\"question\": \"provide 5 great subject lines for our new customers.\"}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        pprint(f\"Finished running: {key}:\")\n",
        "pprint(value[\"generation\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7_1w-EdczhA",
        "outputId": "b9094e0c-acd7-4905-ae19-88ccf450055f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---ROUTE QUESTION---\n",
            "provide 5 great subject lines for our new customers.\n",
            "{'datasource': 'vectorstore'}\n",
            "vectorstore\n",
            "---ROUTE QUESTION TO RAG---\n",
            "---RETRIEVE---\n",
            "'Finished running: retrieve:'\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: GENERATE---\n",
            "'Finished running: grade_documents:'\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "'Finished running: generate:'\n",
            "('Here are five great subject lines for your new customers:\\n'\n",
            " '\\n'\n",
            " '1. Welcome to [community]! Your welcome offer is inside.\\n'\n",
            " \"2. We're so excited you're here, [name]! Thanks for signing up - here's 10% \"\n",
            " 'off.\\n'\n",
            " \"3. Hooray! You're on our email list. Your welcome offer is waiting.\\n\"\n",
            " \"4. Thanks for joining us, [name]! We're thrilled to have you on board.\\n\"\n",
            " '5. Your welcome offer is here! Thanks for choosing [community].\\n'\n",
            " '\\n'\n",
            " \"These subject lines are personalized with the customer's name, making them \"\n",
            " 'more engaging and attention-grabbing. They also clearly communicate the '\n",
            " 'purpose of the email, which is to welcome the new customer and provide them '\n",
            " 'with a special offer.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Body Content Generation using multi-agent CrewAI Agents\n",
        "\n",
        "\n",
        "1.   CrewAI is an easier way to create agents\n",
        "2.   Can be buggy with a lot of hallucinations - use with LangGraph\n",
        "\n"
      ],
      "metadata": {
        "id": "2QW3-jfXYuLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --q crewai\n",
        "!pip install --q crewai-tools\n",
        "!pip install --q -U duckduckgo-search\n",
        "!pip install --q langchain_google_genai\n",
        "!pip install google-api-python-client"
      ],
      "metadata": {
        "id": "G_vdW1UgdWnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from crewai_tools import tool"
      ],
      "metadata": {
        "id": "HgebBhLXZlbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gemini_webapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KSrLrzV5VJU",
        "outputId": "80c2f657-0b95-4c4f-9c06-29735996a4db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gemini_webapi\n",
            "  Downloading gemini_webapi-1.2.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m709.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from gemini_webapi) (0.27.0)\n",
            "Requirement already satisfied: pydantic>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from gemini_webapi) (2.7.1)\n",
            "Collecting loguru>=0.7.2 (from gemini_webapi)\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->gemini_webapi) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->gemini_webapi) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->gemini_webapi) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->gemini_webapi) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->gemini_webapi) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.2->gemini_webapi) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.5.3->gemini_webapi) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.5.3->gemini_webapi) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.5.3->gemini_webapi) (4.11.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.2->gemini_webapi) (1.2.1)\n",
            "Installing collected packages: loguru, gemini_webapi\n",
            "Successfully installed gemini_webapi-1.2.0 loguru-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "from googleapiclient.discovery import build\n",
        "from crewai_tools import (\n",
        "    DirectoryReadTool,\n",
        "    FileReadTool,\n",
        "    SerperDevTool,\n",
        "    WebsiteSearchTool,\n",
        "    BaseTool\n",
        ")\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "aY37jn5qaFUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool('DuckDuckGoSearchRun')\n",
        "def search_tool(search_query: str):\n",
        "  \"search the web on a given topic\"\n",
        "  return DuckDuckGoSearchRun().run(search_query)"
      ],
      "metadata": {
        "id": "dk4kZouBq2b2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set gemini pro as llm\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
        "                             verbose = True,\n",
        "                             temperature = 0.3,\n",
        "                             google_api_key=\"AIzaSyDJ1dXIIgYnes-tThmqYih15S71gJQe-zs\")"
      ],
      "metadata": {
        "id": "mxlQDAoiZrFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C_XBpcoaAis",
        "outputId": "32780006-b015-4fb1-dd41-46bd4d9c6633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGoogleGenerativeAI(verbose=True, model='models/gemini-pro', google_api_key=SecretStr('**********'), temperature=0.3, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x791e54527eb0>, async_client=<google.ai.generativelanguage_v1beta.services.generative_service.async_client.GenerativeServiceAsyncClient object at 0x791e5463df30>, default_metadata=())"
            ]
          },
          "metadata": {},
          "execution_count": 553
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# docs_tool = DirectoryReadTool(directory='/content/drive/MyDrive/Colab Notebooks/html_code')"
      ],
      "metadata": {
        "id": "fHWM0Ss9_1Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your agents with roles and goals\n",
        "sl_creator = Agent(\n",
        "  role='Email Subject Line creator that sticks to the task at hand',\n",
        "  goal='Uncover best examples in creating email subject lines and produce best subject lines that are creative and engaging',\n",
        "  backstory=\"\"\"You work at a leading phone company. Find the information on best examples for a research topic on the internet,\n",
        "  then create subject lines that follow the best examples for the user input.\n",
        "  Your expertise lies in best examples in creating email subject lines based on product type, campaign type, offer, and segment type. Be sure to follow\n",
        "  all of the user's instructions.\n",
        "  You have a knack for collecting information on best examples on subject line that generates the\n",
        "  most engagement and conversions. Your output is 20 concise different subject lines, nothing else and no premable or explaination.\n",
        "  Very important: when searching the internet, the format is just one string 'query'.\n",
        "  Keep searching until you get a response.\n",
        "  Must include some information about the campaign, segment, and offer that the user has given to you.\n",
        "  Do NOT use information about campaign, segment, and offer that is not given by the user.\"\"\",\n",
        "  verbose=True,\n",
        "  allow_delegation=False,\n",
        "  llm = llm,  #using google gemini pro API\n",
        "  tools=[\n",
        "        search_tool\n",
        "      ]\n",
        "  # You can pass an optional llm attribute specifying what mode you wanna use.\n",
        "  # It can be a local model through Ollama / LM Studio or a remote\n",
        "  # model like OpenAI, Mistral, Antrophic of others (https://python.langchain.com/docs/integrations/llms/)\n",
        "  #\n",
        "  # Examples:\n",
        "  # llm=ollama_llm # was defined above in the file\n",
        "  # llm=ChatOpenAI(model_name=\"gpt-3.5\", temperature=0.7)\n",
        ")"
      ],
      "metadata": {
        "id": "rrHzQk6VaInH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0UF1JaRYtrar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your agents with roles and goals\n",
        "preheader_creator = Agent(\n",
        "  role='Pre-header Content Creator that sticks to the task at hand',\n",
        "  goal='Uncover best examples in creating email Pre-header that matches the subject lines that is captivating and engaging',\n",
        "  backstory=\"\"\"You work at a leading phone company.  Find the information on best practices for a research topic on the internet, then create preheaders that follow the best practices.\n",
        "  If the search doesn't respond with a good answer, then create the best pre-headers you can.\n",
        "  You will be given 20 different subject lines.\n",
        "  Be sure to follow all of the user's instructions.\n",
        "  Your expertise lies in best practices in creating email pre-header content based on subject line, segment type.\n",
        "  You have a knack for collecting information on best practices on email pre-header that generates the\n",
        "  most engagement and conversions. Pre-header should support the subject line, but not be the same as the subject line.\n",
        "  You provide the best email preheaders based on each subject line and provide the subject line\n",
        "  and preheader for each subject line, nothing else and no premable or explaination.\n",
        "  Very important: when searching the internet, the format is just one string 'query'.\n",
        "  Keep searching until you get a response.\n",
        "  Must include some information about the campaign, segment, and offer that the user has given to you.\n",
        "  Do NOT use information about campaign, segment, and offer that is not given by the user\"\"\",\n",
        "  verbose=True,\n",
        "  allow_delegation=False,\n",
        "  llm = llm,  #using google gemini pro API\n",
        "  tools=[\n",
        "        search_tool\n",
        "      ]\n",
        "  # You can pass an optional llm attribute specifying what mode you wanna use.\n",
        "  # It can be a local model through Ollama / LM Studio or a remote\n",
        "  # model like OpenAI, Mistral, Antrophic of others (https://python.langchain.com/docs/integrations/llms/)\n",
        "  #\n",
        "  # Examples:\n",
        "  # llm=ollama_llm # was defined above in the file\n",
        "  # llm=ChatOpenAI(model_name=\"gpt-3.5\", temperature=0.7)\n",
        ")"
      ],
      "metadata": {
        "id": "t5iZTLiWbMFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "body_content_generator = Agent(\n",
        "  role='Body Content Generator  that sticks to the task at hand',\n",
        "  goal='Uncover the best practices in email body content generation and uncover best features of the product that matches the subject line and pre-header pairs by reseaching the internet.',\n",
        "  backstory=\"\"\"You work at a leading phone company. Find the best product features on the internet and base the body content around the best product features.\n",
        "  Your expertise lies in best practices in creating email body content based on subject line, pre-header, and segment type.\n",
        "  Be sure to follow all of the user's instructions.\n",
        "  You have a knack for collecting information on best practices on email body content that generates the\n",
        "  most engagement and conversions. Be creative and make sure that each version's body content is different from each other.\n",
        "  You will receive 20 subject lines and pre-headers. Stick to those subject lines and pre-headers. each subject line and preheader is a version.\n",
        "   Body content should support the subject line, pre-header, product's best features, and why they should buy now.\n",
        "  You provide the best email body content based on each subject line, pre-headers, and product features, then provide the subject line\n",
        "  , preheader, and body content, for each subject line preheader pairs and the corresponding version, nothing else and no premable or explaination.\n",
        "  Very important: when searching the internet, the format is just one string 'query'. Keep searching until you get a response.\n",
        "  Must include some information about the campaign, segment, and offer that the user has given to you.\n",
        "  Do NOT use information about campaign, segment, and offer that is not given by the user.\"\"\",\n",
        "  verbose=True,\n",
        "  allow_delegation=False,\n",
        "  llm = llm,  #using google gemini pro API\n",
        "  tools=[\n",
        "      search_tool\n",
        "  ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "ERxMilv8kmVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hero_image_fetcher = Agent(\n",
        "#   role='Hero Image Link Generator',\n",
        "#   goal='Return the best image of the product being marketed to be used in a email campaign',\n",
        "#   backstory=\"\"\"You work at a leading phone company. Find the best hero-image for the product being marketed by searching the internet and getting links for product images to be used in a email campaign.\n",
        "#   Your expertise lies in best practices in getting the best hero-image html link to the image only, not the entire page, be used in an email based on each version's content.\n",
        "#   Do not use images with links that contain imgur.com or other image hosting sites.\n",
        "#   You have a knack for collecting information on best practices on hero images for email campaigns that generates the\n",
        "#   most engagement and conversions. Hero-image should support information in each version. You need to provide a link to the image that can directly be used in an html email optimized for mobile.\n",
        "#   You provide the best hero-image link based on each subject line, pre-headers, and body content, then provide the subject line\n",
        "#   , preheader, body content, and hero-image link, for each subject line preheader and body content pairs, nothing else and no premable or explaination.\"\"\",\n",
        "#   verbose=True,\n",
        "#   allow_delegation=False,\n",
        "#   llm = llm,  #using google gemini pro API\n",
        "#   tools=[\n",
        "#       image_tool\n",
        "#   ]\n",
        "# )\n"
      ],
      "metadata": {
        "id": "hs53OcI8kUoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wl3YEN5RzC7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hero_image_force = Agent(\n",
        "#   role='Hero Image Link attacher',\n",
        "#   goal='Attach a link to all versions',\n",
        "#   backstory=\"\"\"all you do is attach the hero image link : 'https://images.samsung.com/is/image/samsung/p6pim/ca/2202/gallery/ca-galaxy-s22-ultra-s908-sm-s908wdraxac-530780086?$330_330_JPG$'\n",
        "#   to all versions. You will be given 20 different versions of emails. attach the url to each result.\"\"\",\n",
        "#   verbose=True,\n",
        "#   allow_delegation=False,\n",
        "#   llm = llm,  #using google gemini pro API\n",
        "#   tools=[]\n",
        "# )\n"
      ],
      "metadata": {
        "id": "MFWzuYNKzNlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logo_image_force = Agent(\n",
        "#   role='Hero Image Link attacher',\n",
        "#   goal='Attach a link to all versions',\n",
        "#   backstory=\"\"\"all you do is attach the logo image link : 'https://images.samsung.com/is/image/samsung/assets/global/about-us/brand/logo/300_186_2.png?$568_N_PNG$'\n",
        "#   to all versions. You will be given 20 different versions of emails. attach the logo url to each result.\"\"\",\n",
        "#   verbose=True,\n",
        "#   allow_delegation=False,\n",
        "#   llm = llm,  #using google gemini pro API\n",
        "#   tools=[]\n",
        "# )"
      ],
      "metadata": {
        "id": "bsFuh1Ymmn3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# html_generator = Agent(\n",
        "#   role='Email HTML code Generator',\n",
        "#   goal='Create a beautifully designed email in HTML and provide full code',\n",
        "#   backstory=\"\"\"You are a renowned email designer and coder, known for your HTML coding expertise and design knowledge. You thoroughly search online multiple times\n",
        "#   for papers and design trends to get the knowledge on creating the best emails and you apply that knowledge to create the best emails. You resize images and call to action buttons to based on best practices.\n",
        "#   You use Samsung Sans font for all the text. You resize text and images based on best practices.\n",
        "#   You take each version of the email and create the most beautiful and engaging emails based on the subject line, pre-header, and body content.\n",
        "#   You take the logo and image and place them in the email with the subject line, pre-header, and body content, all in the correct places based on best practices.\n",
        "#   You center Call to Action buttons and match image color to make beautiful designs.\n",
        "#   Based on best practices, you use beautiful background graphics and colors to create an effective email in HTML and provide the full code.\n",
        "#   \"\"\",\n",
        "#   verbose=True,\n",
        "#   allow_delegation=False,\n",
        "#   llm = llm,  #using google gemini pro API\n",
        "#   tools=[\n",
        "#       search_tool, docs_tool\n",
        "#   ]\n",
        "# )\n"
      ],
      "metadata": {
        "id": "M6rP1P75k2hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# task1 = Task(\n",
        "#   description=\"\"\"Create 5 subject lines for the upcoming S22 Ultra Launch. This is a pre-order type campaign.\n",
        "#   Product is Samsung Galaxy S22 Ultra and pre-order starts 1/4/2022. The segment type is loyal upgraders, people who upgrade\n",
        "#   during the pre-order phase within 1 or 2 years, and they have a high trade in value. The offer is extra $150 off to pre-order.\"\"\",\n",
        "#   agent=sl_creator,\n",
        "#   expected_output=\"\"\"Subject Line 1\\nSubject Line 2\\nSubject Line 3\\nSubject Line 4\\nSubject Line 5\n",
        "#                   \\nSubject Line 6\\nSubject Line 7\\nSubject Line 8\\nSubject Line 9\\nSubject Line 10\n",
        "#                   \\nSubject Line 11\\nSubject Line 12\\nSubject Line 13\\nSubject Line 14\\nSubject Line 15\n",
        "#                   \\nSubject Line 16\\nSubject Line 17\\nSubject Line 18\\nSubject Line 19\\nSubject Line 20\n",
        "#                   \"\"\"\n",
        "\n",
        "# )"
      ],
      "metadata": {
        "id": "0GAv7Ef9f_zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##Parameters\n",
        "segment = 'first_responders'\n",
        "campaign_goal = 'GalaxyBook and Tablet Sales Event'\n",
        "campaign_type = 'Sales event for first responder customers with Employee Pricing Program Accounts'\n",
        "campaign_type = 'Sales event'\n",
        "offer_description = 'giving up to 60% off all Samsung products'\n",
        "segment_type = 'First responder members with Employee Pricing Program Accounts'\n",
        "segment_description = 'Appreciating our First Responders for protecting all of us.'\n",
        "offer = 'Additional 20% off when you buy a Galaxy Book and Tablet'\n",
        "offer_expiration = 'The offer is only valid for one week'\n",
        "product_type = 'All Galaxy Books and Tablets.'\n",
        "must_include = 'You must include Thank you for your bravery in the subject line'\n",
        "do_not_include = 'Do not include the segment name in the subject line'\n",
        "additional_info = \"You must include the features of best Samsung products and tailor the content to first responders.\"\n"
      ],
      "metadata": {
        "id": "7zkG_LQO-uFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task1 = Task(\n",
        "  description=f\"\"\"Create 20 subject lines {campaign_goal}. This is a {campaign_type} campaign.\n",
        "  We will be {offer_description}. The segment type is {segment_type}, who are {segment_description}.\n",
        "  The offer is a {offer} on {product_type}. {must_include} in the subject line. {offer_expiration}\n",
        "  {do_not_include}. Stick to the offers given to you by me, we don't have any other offers.\"\"\",\n",
        "  agent=sl_creator,\n",
        "  expected_output=\"\"\"Subject Line 1\\nSubject Line 2\\nSubject Line 3\\nSubject Line 4\\nSubject Line 5\n",
        "                  \\nSubject Line 6\\nSubject Line 7\\nSubject Line 8\\nSubject Line 9\\nSubject Line 10\n",
        "                  \\nSubject Line 11\\nSubject Line 12\\nSubject Line 13\\nSubject Line 14\\nSubject Line 15\n",
        "                  \\nSubject Line 16\\nSubject Line 17\\nSubject Line 18\\nSubject Line 19\\nSubject Line 20\n",
        "                  \"\"\")"
      ],
      "metadata": {
        "id": "wRuMbJflkzH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task2 = Task(\n",
        "  description=f\"\"\"Using the subject line provided, create a concise pre-header for each subject line\n",
        "  and give me a pair of subject line and paired preheader.The segment type is {segment_type}, {segment_description}. This is a {campaign_type}.\n",
        " {offer} {offer_description} {offer_expiration}\n",
        " Do not include the segment name in the preheader.Stick to the offers given to you by me, we don't have any other offers.\n",
        " \"\"\",\n",
        "  agent=preheader_creator,\n",
        "  expected_output=\"\"\"{Subject Line 1} -- {Pre-Header 1}\\n\n",
        "                      {Subject Line 2} -- {Pre-Header 2}\\n\n",
        "                      {Subject Line 3} -- {Pre-Header 3}\\n\n",
        "                      {Subject Line 4} -- {Pre-Header 4}\\n\n",
        "                      {Subject Line 5} -- {Pre-Header 5}\\n\n",
        "                      {Subject Line 6} -- {Pre-Header 6}\\n\n",
        "                      {Subject Line 7} -- {Pre-Header 7}\\n\n",
        "                      {Subject Line 8} -- {Pre-Header 8}\\n\n",
        "                      {Subject Line 9} -- {Pre-Header 9}\\n\n",
        "                      {Subject Line 10} -- {Pre-Header 10}\\n\n",
        "                      {Subject Line 11} -- {Pre-Header 11}\\n\n",
        "                      # {Subject Line 12} -- {Pre-Header 12}\\n\n",
        "                      {Subject Line 13} -- {Pre-Header 13}\\n\n",
        "                      {Subject Line 14} -- {Pre-Header 14}\\n\n",
        "                      {Subject Line 15} -- {Pre-Header 15}\\n\n",
        "                      {Subject Line 16} -- {Pre-Header 16}\\n\n",
        "                      {Subject Line 17} -- {Pre-Header 17}\\n\n",
        "                      {Subject Line 18} -- {Pre-Header 18}\\n\n",
        "                      {Subject Line 19} -- {Pre-Header 19}\\n\n",
        "                      {Subject Line 20} -- {Pre-Header 20}\\n \"\"\" )\n"
      ],
      "metadata": {
        "id": "wzSP-uSJBWQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task3 = Task(\n",
        "  description=f\"\"\"Using the subject line and preheader provided, create a concise body content for each subject line\n",
        "  and pre header, then give me a pair of subject line and paired preheader.\n",
        "  The segment type is {segment_type}, {segment_description}. {additional_info}. {offer_expiration}\n",
        "  Stick to the offers given to you by me, we don't have any other offers.\"\"\",\n",
        "  agent=body_content_generator,\n",
        "  expected_output=\"\"\"Version 1 : --SL {Subject Line 1} --PH: {Pre-Header 1} --B:{Body Content 1}\\n\n",
        "                      Version 2 : --SL {Subject Line 2} --PH: {Pre-Header 2} --B:{Body Content 2}\\n\n",
        "                      Version 3 : --SL {Subject Line 3} --PH: {Pre-Header 3} --B:{Body Content 3}\\n\n",
        "                      Version 4 : --SL {Subject Line 4} --PH: {Pre-Header 4} --B:{Body Content 4}\\n\n",
        "                      Version 5 : --SL {Subject Line 5} --PH: {Pre-Header 5} --B:{Body Content 5}\\n\n",
        "                      Version 6 : --SL {Subject Line 6} --PH: {Pre-Header 6} --B:{Body Content 6}\\n\n",
        "                      Version 7 : --SL {Subject Line 7} --PH: {Pre-Header 7} --B:{Body Content 7}\\n\n",
        "                      Version 8 : --SL {Subject Line 8} --PH: {Pre-Header 8} --B:{Body Content 8}\\n\n",
        "                      Version 9 : --SL {Subject Line 9} --PH: {Pre-Header 9} --B:{Body Content 9}\\n\n",
        "                      Version 10 : --SL {Subject Line 10} --PH: {Pre-Header 10} --B:{Body Content 10}\\n\n",
        "                      Version 11 : --SL {Subject Line 11} --PH: {Pre-Header 11} --B:{Body Content 11}\\n\n",
        "                      Version 12 : --SL {Subject Line 12} --PH: {Pre-Header 12} --B:{Body Content 12}\\n\n",
        "                      Version 13 : --SL {Subject Line 13} --PH: {Pre-Header 13} --B:{Body Content 13}\\n\n",
        "                      Version 14 : --SL {Subject Line 14} --PH: {Pre-Header 14} --B:{Body Content 14}\\n\n",
        "                      Version 15 : --SL {Subject Line 15} --PH: {Pre-Header 15} --B:{Body Content 15}\\n\n",
        "                      Version 16 : --SL {Subject Line 16} --PH: {Pre-Header 16} --B:{Body Content 16}\\n\n",
        "                      Version 17 : --SL {Subject Line 17} --PH: {Pre-Header 17} --B:{Body Content 17}\\n\n",
        "                      Version 18 : --SL {Subject Line 18} --PH: {Pre-Header 18} --B:{Body Content 18}\\n\n",
        "                      Version 19 : --SL {Subject Line 19} --PH: {Pre-Header 19} --B:{Body Content 19}\\n\n",
        "                      Version 20 : --SL {Subject Line 20} --PH: {Pre-Header 20} --B:{Body Content 20}\\n\"\"\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "CB70OaLcltr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "  agents=[sl_creator, preheader_creator,body_content_generator],\n",
        "  tasks=[task1, task2, task3],\n",
        "  verbose=2, # You can set it to 1 or 2 to different logging levels\n",
        ")"
      ],
      "metadata": {
        "id": "v2Zk7W_XfyAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343fc050-4a12-4c7c-f288-ae7610db9f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crew"
      ],
      "metadata": {
        "id": "TR6B3B5TjRIr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42408def-9dcf-4e68-f089-1614197b376a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Crew(id=ea44ed5c-4f4b-46d2-b48a-fafae8bf1f1f, process=sequential, number_of_agents=3, number_of_tasks=3)"
            ]
          },
          "metadata": {},
          "execution_count": 569
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = crew.kickoff()"
      ],
      "metadata": {
        "id": "sP6caDDyjSrw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0c0941-53c1-45c7-b65a-aae6957fed1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Email Subject Line creator that sticks to the task at hand\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Create 20 subject lines GalaxyBook and Tablet Sales Event. This is a Sales event campaign.\n",
            "  We will be giving up to 60% off all Samsung products. The segment type is First responder members with Employee Pricing Program Accounts, who are Appreciating our First Responders for protecting all of us.. \n",
            "  The offer is a Additional 20% off when you buy a Galaxy Book and Tablet on All Galaxy Books and Tablets.. You must include Thank you for your bravery in the subject line in the subject line. The offer is only valid for one week\n",
            "  Do not include the segment name in the subject line. Stick to the offers given to you by me, we don't have any other offers.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: DuckDuckGoSearchRun\n",
            "Action Input: {\"search_query\": \"best examples email subject lines\"}\u001b[0m\u001b[95m \n",
            "\n",
            "Here are great examples to nail your sales subject line for your email campaign: \"You Have Two Choices.\". Everyone loves to play games, and everyone likes to have options. This is a great subject line for sales, as choices influence people to take action. \"Why You Can't [insert problem here]\" Why you can't lose weight. Regardless of your goals, these are the essential elements that your subject line should possess. 1. Urgency. Creating a sense of urgency is an efficient way to get people to take action. Subject lines that use words like \"urgent,\" \"breaking,\" \"important,\" or \"alert\" have higher open rates. Email Subject Line Examples By Category. We also have some more catchy email subject line examples from great brands and marketers, categorized for you: 1. Professional email subject lines \"[Action Required] Verify your email address\" — Amazon Chime \"Your free PDF is attached: Great Talks Most Pople have Never Heard\" — James Clear; 2. Welcome email subject lines should help solidify a bond between subscriber and business. \"Thank you for joining [company name]! Here's what we have in store for you.\". \"Welcome to [company name] - Let's make great things happen together.\". \"Welcome [name]! Your success story begins here.\". With the number of emails sent daily, those that grab the recipient's attention will most likely be opened. For example: \"Boost Your Bottom-line with this One Proven Technique by 50%\" is more likely to entice your email recipient to open your email than an email subject line that simply says \"Quick Question\".\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought:\n",
            "Action: DuckDuckGoSearchRun\n",
            "Action Input: {\"search_query\": \"best examples email subject lines for sales event\"}\u001b[0m\u001b[95m \n",
            "\n",
            "150 Sales Email Subject Lines That Get Opened, Read, and Responded To. There's one email feature that can prevent your email from going straight to your recipient's \"Junk\" folder. That tool is an email subject line, and it's one of the most important parts of your sales email. Your open rate, click rate, and CTA conversions depend on ... 1. Urgency. Limited-time offers are a great way to inspire immediate action (and purchases!). Here are some examples of the best email subject lines for sales that manage to capture attention, offer an incentive, and create urgency: Counting down the hours … 50% off won't last. Set your alarm for our sales event! 1. Choose language carefully. Language matters, especially when you're trying to convince someone to open a sales or marketing email. And in the age of phishing schemes and ransomware, people are on high alert regarding the language used in emails. Be careful what language you use in your subject lines, especially regarding: Keywords: While ... 3. \"Invitation to [webinar or event]\". If you know your prospective client could benefit from an event or webinar your company is hosting or is affiliated with, include it as a subject line. Providing value from the get-go is key, and it shows your thoughtfulness. 4. \"A glimpse of what's to come.\". 90 Catchy Email Subject Lines for Event. Crafting catchy email subject lines for events is crucial for ensuring you stands out in a crowded inbox. A good subject line can dramatically increase open rates. Below are types of subject lines tailored for different emails, each accompanied by three examples: The \"Announcement\" Subject line Examples\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now can give a great answer\n",
            "Final Answer: \n",
            "Subject Line 1 Thank you for your bravery! Up to 60% off Galaxy Books and Tablets\n",
            "Subject Line 2 Thank you for your bravery! Save an extra 20% on Galaxy Books and Tablets\n",
            "Subject Line 3 Thank you for your bravery! Galaxy Book and Tablet Sales Event\n",
            "Subject Line 4 Thank you for your bravery! Don't miss out on 60% off Galaxy Books and Tablets\n",
            "Subject Line 5 Thank you for your bravery! Your exclusive offer on Galaxy Books and Tablets\n",
            "Subject Line 6 Thank you for your bravery! Time is running out on Galaxy Book and Tablet savings\n",
            "Subject Line 7 Thank you for your bravery! Last chance to save on Galaxy Books and Tablets\n",
            "Subject Line 8 Thank you for your bravery! Galaxy Book and Tablet Sale ends soon\n",
            "Subject Line 9 Thank you for your bravery! Get your Galaxy Book and Tablet today\n",
            "Subject Line 10 Thank you for your bravery! Don't miss out on these Galaxy Book and Tablet deals\n",
            "Subject Line 11 Thank you for your bravery! Up to 60% off Galaxy Books and Tablets for a limited time\n",
            "Subject Line 12 Thank you for your bravery! Save on Galaxy Books and Tablets with this exclusive offer\n",
            "Subject Line 13 Thank you for your bravery! Galaxy Book and Tablet Sale is now on\n",
            "Subject Line 14 Thank you for your bravery! Get the Galaxy Book and Tablet you've always wanted\n",
            "Subject Line 15 Thank you for your bravery! Galaxy Books and Tablets are on sale now\n",
            "Subject Line 16 Thank you for your bravery! Don't miss out on these amazing Galaxy Book and Tablet deals\n",
            "Subject Line 17 Thank you for your bravery! Galaxy Book and Tablet Sale is ending soon\n",
            "Subject Line 18 Thank you for your bravery! Last chance to save on Galaxy Books and Tablets\n",
            "Subject Line 19 Thank you for your bravery! Get your Galaxy Book and Tablet today\n",
            "Subject Line 20 Thank you for your bravery! Don't miss out on these Galaxy Book and Tablet deals\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Email Subject Line creator that sticks to the task at hand] Task output: Subject Line 1 Thank you for your bravery! Up to 60% off Galaxy Books and Tablets\n",
            "Subject Line 2 Thank you for your bravery! Save an extra 20% on Galaxy Books and Tablets\n",
            "Subject Line 3 Thank you for your bravery! Galaxy Book and Tablet Sales Event\n",
            "Subject Line 4 Thank you for your bravery! Don't miss out on 60% off Galaxy Books and Tablets\n",
            "Subject Line 5 Thank you for your bravery! Your exclusive offer on Galaxy Books and Tablets\n",
            "Subject Line 6 Thank you for your bravery! Time is running out on Galaxy Book and Tablet savings\n",
            "Subject Line 7 Thank you for your bravery! Last chance to save on Galaxy Books and Tablets\n",
            "Subject Line 8 Thank you for your bravery! Galaxy Book and Tablet Sale ends soon\n",
            "Subject Line 9 Thank you for your bravery! Get your Galaxy Book and Tablet today\n",
            "Subject Line 10 Thank you for your bravery! Don't miss out on these Galaxy Book and Tablet deals\n",
            "Subject Line 11 Thank you for your bravery! Up to 60% off Galaxy Books and Tablets for a limited time\n",
            "Subject Line 12 Thank you for your bravery! Save on Galaxy Books and Tablets with this exclusive offer\n",
            "Subject Line 13 Thank you for your bravery! Galaxy Book and Tablet Sale is now on\n",
            "Subject Line 14 Thank you for your bravery! Get the Galaxy Book and Tablet you've always wanted\n",
            "Subject Line 15 Thank you for your bravery! Galaxy Books and Tablets are on sale now\n",
            "Subject Line 16 Thank you for your bravery! Don't miss out on these amazing Galaxy Book and Tablet deals\n",
            "Subject Line 17 Thank you for your bravery! Galaxy Book and Tablet Sale is ending soon\n",
            "Subject Line 18 Thank you for your bravery! Last chance to save on Galaxy Books and Tablets\n",
            "Subject Line 19 Thank you for your bravery! Get your Galaxy Book and Tablet today\n",
            "Subject Line 20 Thank you for your bravery! Don't miss out on these Galaxy Book and Tablet deals\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Pre-header Content Creator that sticks to the task at hand\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Using the subject line provided, create a concise pre-header for each subject line\n",
            "  and give me a pair of subject line and paired preheader.The segment type is First responder members with Employee Pricing Program Accounts, Appreciating our First Responders for protecting all of us.. This is a Sales event.\n",
            " Additional 20% off when you buy a Galaxy Book and Tablet giving up to 60% off all Samsung products The offer is only valid for one week\n",
            " Do not include the segment name in the preheader.Stick to the offers given to you by me, we don't have any other offers.\n",
            " \u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I should search the internet for best practices for a research topic on the internet\n",
            "Action: DuckDuckGoSearchRun(search_query='best practices for a research topic on the internet')\n",
            "Action Input: {}\u001b[0m\u001b[91m \n",
            "\n",
            "Action 'DuckDuckGoSearchRun(search_query='best practices for a research topic on the internet')' don't exist, these are the only available Actions:\n",
            " DuckDuckGoSearchRun: DuckDuckGoSearchRun(search_query: 'string') - search the web on a given topic\n",
            "\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i5mVTpEdrxgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import re\n",
        "\n",
        "# Input string\n",
        "text = \"\"\"\n",
        "Version 1 : --SL {Thank you for your service! Up to 60% off Galaxy Books and Tablets} --PH: {Save big on Samsung Galaxy Books and Tablets, exclusive for Military members with Employee Pricing Program Accounts} --B:{Military members with Employee Pricing Program Accounts, save up to 60% on Samsung Galaxy Books and Tablets. Don't miss out on this limited-time offer. With features like a large OLED touchscreen display, high-performance laptop with discrete GPU, fantastic battery life and efficiency, and useful Samsung features, you'll be able to stay connected and productive wherever you go. Order now and take advantage of this exclusive offer!}\n",
        "\n",
        "                      Version 2 : --SL {Military Exclusive: Save up to 80% on Samsung Galaxy Books and Tablets} --PH: {Exclusive savings for Military members with Employee Pricing Program Accounts, up to 80% off Samsung Galaxy Books and Tablets} --B:{Military members with Employee Pricing Program Accounts, take advantage of this exclusive offer and save up to 80% on Samsung Galaxy Books and Tablets. With features like a large OLED touchscreen display, high-performance laptop with discrete GPU, fantastic battery life and efficiency, and useful Samsung features, you'll be able to stay connected and productive wherever you go. Don't miss out on this limited-time offer. Order now!}\n",
        "\n",
        "                      Version 3 : --SL {Calling all Military Members: Employee Pricing + Extra 20% off Galaxy Books and Tablets} --PH: {Military members with Employee Pricing Program Accounts, save an extra 20% on Samsung Galaxy Books and Tablets} --B:{Military members with Employee Pricing Program Accounts, save an extra 20% on Samsung Galaxy Books and Tablets. With features like a large OLED touchscreen display, high-performance laptop with discrete GPU, fantastic battery life and efficiency, and useful Samsung features, you'll be able to stay connected and productive wherever you go. This offer is only valid for a limited time, so don't miss out. Order now!}\n",
        "\n",
        "                      Version 4 : --SL {Thank you for your service! Limited-time offer: Up to 60% off Galaxy Books and Tablets} --PH: {Don't miss out, Military members with Employee Pricing Program Accounts, up to 60% off Samsung Galaxy Books and Tablets} --B:{Military members with Employee Pricing Program Accounts, don't miss out on this limited-time offer and save up to 60% on Samsung Galaxy Books and Tablets. With features like a large OLED touchscreen display, high-performance laptop with discrete GPU, fantastic battery life and efficiency, and useful Samsung features, you'll be able to stay connected and productive wherever you go. Order now!}\n",
        "\n",
        "                      Version 5 : --SL {Military Appreciation Sale: Save up to 80% on Samsung Galaxy Books and Tablets} --PH: {Military Appreciation Sale, save up to 80% on Samsung Galaxy Books and Tablets, exclusive for Military members with Employee Pricing Program Accounts} --B:{Military members with Employee Pricing Program Accounts, take advantage of this exclusive Military Appreciation Sale and save up to 80% on Samsung Galaxy Books and Tablets. With features like a large OLED touchscreen display, high-performance laptop with discrete GPU, fantastic battery life and efficiency, and useful Samsung features, you'll be able to stay connected and productive wherever you go. Don't miss out on this limited-time offer. Order now!}\n",
        "\n",
        "                      Version 6 : --SL {Exclusive for Military: Employee Pricing + Extra 20% off Galaxy Books and Tablets} --PH: {Exclusive offer for Military members with Employee Pricing Program Accounts, save an extra 20% on Samsung Galaxy Books and Tablets} --B:{Military members with Employee Pricing Program Accounts, take advantage of this exclusive offer and save an extra 20% on Samsung Galaxy Books and Tablets. With features like a large OLED touchscreen display, high-performance laptop with discrete GPU, fantastic battery life and efficiency, and useful Samsung features, you'll be able to stay connected and productive wherever you go. Don't miss out on this limited-time offer. Order now!}\n",
        "\n",
        "                      Version 7 : --SL {Thank you for your service! Don't miss out on up to 60% off Galaxy Books and Tablets} --PH: {Time is running out, Military members with Employee Pricing Program Accounts, up to 60% off Samsung Galaxy Books and Tablets} --B:{Military members with Employee Pricing Program Accounts, don't miss out on this limited-time offer and save up to 60% on Samsung Galaxy Books and Tablets. With features like a large OLED touchscreen display, high-performance laptop with discrete GPU, fantastic battery life and efficiency, and useful Samsung features, you'll be able to stay connected and productive wherever you go. Order now!}\n",
        "\n",
        "                      Version 8 : --SL {Military Members: Save up to 80% on Samsung Galaxy Books and Tablets} --PH: {Military members with Employee Pricing Program Accounts, save up to 80% on Samsung Galaxy Books and Tablets} --B:{Military members with Employee Pricing Program Accounts, take advantage of this exclusive offer and save up to 80% on Samsung Galaxy Books and Tablets. With features like a large OLED touchscreen display, high-performance laptop with discrete GPU, fantastic battery life and efficiency, and useful Samsung features, you'll be able to stay connected and productive wherever you go. Don't miss out on this limited-time offer. Order now!}\n",
        "\n",
        "                      Version 9 : --SL {Calling all Military Members: Employee Pricing + Extra 20% off Galaxy Books and Tablets} --PH: {Calling all Military members with Employee Pricing Program Accounts, save an extra 20% on Samsung Galaxy Books and Tablets} --B:{Military members with Employee Pricing Program Accounts, save an extra 20% on Samsung Galaxy Books and Tablets. With features like a large OLED touchscreen display, high-performance laptop with discrete GPU, fantastic battery life and efficiency, and useful Samsung features, you'll be able to stay connected and productive wherever you go. This offer is only valid for a limited time, so don't miss out. Order now!}\n",
        "\n",
        "                      Version 10 : --SL {Thank you for your service! Limited-time offer: Up to 60% off Galaxy Books and Tablets} --PH: {Military members with Employee Pricing Program Accounts, don't miss out, up to 60% off Samsung Galaxy Books and Tablets} --B:{Military members with Employee Pricing Program Accounts, don't miss out on this limited-time offer and save up to 60% on Samsung Galaxy Books and Tablets. With features like a large OLED touchscreen display, high-performance laptop with discrete GPU, fantastic battery life and efficiency, and useful Samsung features, you'll be able to stay connected and productive wherever you go. Order now!}\n",
        "\n",
        "                      Version 11 : --SL {Military Appreciation Sale: Save up to 80% on Samsung Galaxy Books and Tablets} --PH: {Military Appreciation Sale, save up to 80% on Samsung Galaxy Books and Tablets, exclusive for Military members with Employee Pricing Program Accounts} --B:{Military members with Employee Pricing Program Accounts, take advantage of this exclusive Military Appreciation Sale and save up to 80% on Samsung Galaxy Books and Tablets. With features like a large OLED touchscreen display, high-performance laptop with discrete GPU, fantastic battery life and efficiency, and useful Samsung features, you'll be able to stay connected and productive wherever you go. Don't miss out on this limited-time offer. Order now!}\n",
        "\n",
        "                      Version 12 : --SL {Exclusive for Military: Employee Pricing + Extra 20% off Galaxy Books and Tablets} --PH: {Exclusive offer for Military members with Employee Pricing Program Accounts, save an extra 20% on Samsung Galaxy Books and Tablets} --B:{Military members with Employee Pricing Program Accounts, take advantage of this exclusive offer and save an extra 20% on Samsung Galaxy Books and Tablets. With features like a large OLED touchscreen display, high-performance laptop with discrete GPU, fantastic battery life and efficiency, and useful Samsung features, you'll be able to stay connected and productive wherever you go. Don't miss out on this limited-time offer. Order now!}\n",
        "\n",
        "                      Version 13 : --SL {Thank you for your service! Don't miss out on up to 60% off Galaxy Books and Tablets} --PH: {Time is running out, Military members with Employee Pricing Program Accounts, up to 60% off Samsung Galaxy Books and Tablets} --B:{Military members with Employee Pricing Program Accounts, don't miss out on this limited-time offer and save up to 60% on Samsung Galaxy Books and Tablets. With features like a large OLED touchscreen display, high-performance laptop with discrete GPU, fantastic battery life and efficiency, and useful Samsung features, you'll be able to stay connected and productive wherever you go. Order now!}\n",
        "\n",
        "                      Version 14 : --SL {Military Members: Save up to 80% on Samsung Galaxy Books and Tablets} --PH: {Military members with Employee Pricing Program Accounts, save up to 80% on Samsung Galaxy Books and Tablets} --B:{Military members with Employee Pricing Program Accounts, take advantage of this exclusive offer and save up to 80% on Samsung Galaxy Books and Tablets. With features like a large OLED touchscreen display, high-performance laptop with discrete GPU, fantastic battery life and efficiency, and useful Samsung features, you'll be able to stay connected and productive wherever you go. Don't miss out on this limited-time offer. Order now!}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# Split the text into versions\n",
        "versions = text.split('Version ')[1:]\n",
        "\n",
        "# Extract SL, PH, and Body from each version\n",
        "data = []\n",
        "\n",
        "for version in versions:\n",
        "    version = version.strip()\n",
        "    sl, ph_body = version.split('--PH:')\n",
        "    ph, body = ph_body.split('--B:')\n",
        "    body = body.strip('}')\n",
        "    data.append({\n",
        "        'segment_type': f'{segment}',  # Add a default segment type\n",
        "        'version': version.split(': ')[0],\n",
        "        'SL': sl[5:-1],\n",
        "        'PH': ph,\n",
        "        'Body': body\n",
        "    })\n",
        "\n",
        "# Write to CSV file\n",
        "\n",
        "with open(f'/content/drive/MyDrive/Colab Notebooks/{campaign}.csv', 'a', newline='') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=data[0].keys())\n",
        "    if csvfile.tell() == 0:  # Check if file is empty\n",
        "        writer.writeheader()  # Write the header row\n",
        "    writer.writerows(data)  # Write the data rows"
      ],
      "metadata": {
        "id": "EjxpUdnxjcr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(f'/content/drive/MyDrive/Colab Notebooks/{campaign}.csv')"
      ],
      "metadata": {
        "id": "Ty6Mfn3uV2d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ytmXZSDaWeG4",
        "outputId": "f564e454-f034-41b7-811b-91e212fcbdfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   segment_type  version                                                 SL  \\\n",
              "0      Students        1  -SL {Back to School Sales Event: Save up to 60...   \n",
              "1      Students        2  -SL {Back to School Savings: Get an Additional...   \n",
              "2      Students        3  -SL {Back to School Sale: Samsung Galaxy Books...   \n",
              "3      Students        4  -SL {Back to School Savings: Up to 60% off Sam...   \n",
              "4      Students        5  -SL {Back to School Sale: Save on Samsung Gala...   \n",
              "5      Students        6  -SL {Back to School Savings: Get an Additional...   \n",
              "6      Students        7  -SL {Back to School Sale: Samsung Galaxy Books...   \n",
              "7      Students        8  -SL {Back to School Savings: Up to 60% off Sam...   \n",
              "8      Students        9  -SL {Back to School Sale: Save on Samsung Gala...   \n",
              "9      Students       10  --SL {Back to School Savings: Get an Additiona...   \n",
              "10     Students       11  --SL {Back to School Sale: Samsung Galaxy Book...   \n",
              "11     Students       12  --SL {Back to School Savings: Up to 60% off Sa...   \n",
              "12     Students       13  --SL {Back to School Sale: Save on Samsung Gal...   \n",
              "13     military        1  -SL {Thank you for your service! Up to 60% off...   \n",
              "14     military        2  -SL {Military Exclusive: Save up to 80% on Sam...   \n",
              "15     military        3  -SL {Calling all Military Members: Employee Pr...   \n",
              "16     military        4  -SL {Thank you for your service! Limited-time ...   \n",
              "17     military        5  -SL {Military Appreciation Sale: Save up to 80...   \n",
              "18     military        6  -SL {Exclusive for Military: Employee Pricing ...   \n",
              "19     military        7  -SL {Thank you for your service! Don't miss ou...   \n",
              "20     military        8  -SL {Military Members: Save up to 80% on Samsu...   \n",
              "21     military        9  -SL {Calling all Military Members: Employee Pr...   \n",
              "22     military       10  --SL {Thank you for your service! Limited-time...   \n",
              "23     military       11  --SL {Military Appreciation Sale: Save up to 8...   \n",
              "24     military       12  --SL {Exclusive for Military: Employee Pricing...   \n",
              "25     military       13  --SL {Thank you for your service! Don't miss o...   \n",
              "26     military       14  --SL {Military Members: Save up to 80% on Sams...   \n",
              "\n",
              "                                                   PH  \\\n",
              "0    {Get ready for school with the latest tech at...   \n",
              "1    {Score an extra 20% off on top of our already...   \n",
              "2    {Don't miss out on these incredible deals on ...   \n",
              "3    {Save big on Samsung Galaxy Books and Tablets...   \n",
              "4    {Get the latest Samsung Galaxy Books and Tabl...   \n",
              "5    {Take advantage of our exclusive offer and sa...   \n",
              "6    {Shop now for the best deals on Samsung Galax...   \n",
              "7      {Don't wait, these deals won't last forever!}    \n",
              "8    {Get your hands on the latest Samsung Galaxy ...   \n",
              "9        {Upgrade your tech with our special offer!}    \n",
              "10             {Limited time offer, don't miss out!}    \n",
              "11   {Get ready for school with the latest Samsung...   \n",
              "12   {Don't miss out on these incredible deals on ...   \n",
              "13   {Save big on Samsung Galaxy Books and Tablets...   \n",
              "14   {Exclusive savings for Military members with ...   \n",
              "15   {Military members with Employee Pricing Progr...   \n",
              "16   {Don't miss out, Military members with Employ...   \n",
              "17   {Military Appreciation Sale, save up to 80% o...   \n",
              "18   {Exclusive offer for Military members with Em...   \n",
              "19   {Time is running out, Military members with E...   \n",
              "20   {Military members with Employee Pricing Progr...   \n",
              "21   {Calling all Military members with Employee P...   \n",
              "22   {Military members with Employee Pricing Progr...   \n",
              "23   {Military Appreciation Sale, save up to 80% o...   \n",
              "24   {Exclusive offer for Military members with Em...   \n",
              "25   {Time is running out, Military members with E...   \n",
              "26   {Military members with Employee Pricing Progr...   \n",
              "\n",
              "                                                 Body  \n",
              "0   {Get ready for school with the latest Samsung ...  \n",
              "1   {Get an additional 20% off on top of our alrea...  \n",
              "2   {Don't miss out on these incredible deals on S...  \n",
              "3   {Save big on Samsung Galaxy Books and Tablets,...  \n",
              "4   {Get the latest Samsung Galaxy Books and Table...  \n",
              "5   {Take advantage of our exclusive offer and sav...  \n",
              "6   {Shop now for the best deals on Samsung Galaxy...  \n",
              "7   {Don't wait, these deals on Samsung Galaxy Boo...  \n",
              "8   {Get your hands on the latest Samsung Galaxy B...  \n",
              "9   {Upgrade your tech with our special offer on S...  \n",
              "10  {Limited time offer on Samsung Galaxy Books an...  \n",
              "11  {Get ready for school with the latest Samsung ...  \n",
              "12  {Don't miss out on these incredible deals on S...  \n",
              "13  {Military members with Employee Pricing Progra...  \n",
              "14  {Military members with Employee Pricing Progra...  \n",
              "15  {Military members with Employee Pricing Progra...  \n",
              "16  {Military members with Employee Pricing Progra...  \n",
              "17  {Military members with Employee Pricing Progra...  \n",
              "18  {Military members with Employee Pricing Progra...  \n",
              "19  {Military members with Employee Pricing Progra...  \n",
              "20  {Military members with Employee Pricing Progra...  \n",
              "21  {Military members with Employee Pricing Progra...  \n",
              "22  {Military members with Employee Pricing Progra...  \n",
              "23  {Military members with Employee Pricing Progra...  \n",
              "24  {Military members with Employee Pricing Progra...  \n",
              "25  {Military members with Employee Pricing Progra...  \n",
              "26  {Military members with Employee Pricing Progra...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-531caf63-190b-4cba-b735-efa20e599b4f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>segment_type</th>\n",
              "      <th>version</th>\n",
              "      <th>SL</th>\n",
              "      <th>PH</th>\n",
              "      <th>Body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Students</td>\n",
              "      <td>1</td>\n",
              "      <td>-SL {Back to School Sales Event: Save up to 60...</td>\n",
              "      <td>{Get ready for school with the latest tech at...</td>\n",
              "      <td>{Get ready for school with the latest Samsung ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Students</td>\n",
              "      <td>2</td>\n",
              "      <td>-SL {Back to School Savings: Get an Additional...</td>\n",
              "      <td>{Score an extra 20% off on top of our already...</td>\n",
              "      <td>{Get an additional 20% off on top of our alrea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Students</td>\n",
              "      <td>3</td>\n",
              "      <td>-SL {Back to School Sale: Samsung Galaxy Books...</td>\n",
              "      <td>{Don't miss out on these incredible deals on ...</td>\n",
              "      <td>{Don't miss out on these incredible deals on S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Students</td>\n",
              "      <td>4</td>\n",
              "      <td>-SL {Back to School Savings: Up to 60% off Sam...</td>\n",
              "      <td>{Save big on Samsung Galaxy Books and Tablets...</td>\n",
              "      <td>{Save big on Samsung Galaxy Books and Tablets,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Students</td>\n",
              "      <td>5</td>\n",
              "      <td>-SL {Back to School Sale: Save on Samsung Gala...</td>\n",
              "      <td>{Get the latest Samsung Galaxy Books and Tabl...</td>\n",
              "      <td>{Get the latest Samsung Galaxy Books and Table...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Students</td>\n",
              "      <td>6</td>\n",
              "      <td>-SL {Back to School Savings: Get an Additional...</td>\n",
              "      <td>{Take advantage of our exclusive offer and sa...</td>\n",
              "      <td>{Take advantage of our exclusive offer and sav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Students</td>\n",
              "      <td>7</td>\n",
              "      <td>-SL {Back to School Sale: Samsung Galaxy Books...</td>\n",
              "      <td>{Shop now for the best deals on Samsung Galax...</td>\n",
              "      <td>{Shop now for the best deals on Samsung Galaxy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Students</td>\n",
              "      <td>8</td>\n",
              "      <td>-SL {Back to School Savings: Up to 60% off Sam...</td>\n",
              "      <td>{Don't wait, these deals won't last forever!}</td>\n",
              "      <td>{Don't wait, these deals on Samsung Galaxy Boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Students</td>\n",
              "      <td>9</td>\n",
              "      <td>-SL {Back to School Sale: Save on Samsung Gala...</td>\n",
              "      <td>{Get your hands on the latest Samsung Galaxy ...</td>\n",
              "      <td>{Get your hands on the latest Samsung Galaxy B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Students</td>\n",
              "      <td>10</td>\n",
              "      <td>--SL {Back to School Savings: Get an Additiona...</td>\n",
              "      <td>{Upgrade your tech with our special offer!}</td>\n",
              "      <td>{Upgrade your tech with our special offer on S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Students</td>\n",
              "      <td>11</td>\n",
              "      <td>--SL {Back to School Sale: Samsung Galaxy Book...</td>\n",
              "      <td>{Limited time offer, don't miss out!}</td>\n",
              "      <td>{Limited time offer on Samsung Galaxy Books an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Students</td>\n",
              "      <td>12</td>\n",
              "      <td>--SL {Back to School Savings: Up to 60% off Sa...</td>\n",
              "      <td>{Get ready for school with the latest Samsung...</td>\n",
              "      <td>{Get ready for school with the latest Samsung ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Students</td>\n",
              "      <td>13</td>\n",
              "      <td>--SL {Back to School Sale: Save on Samsung Gal...</td>\n",
              "      <td>{Don't miss out on these incredible deals on ...</td>\n",
              "      <td>{Don't miss out on these incredible deals on S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>military</td>\n",
              "      <td>1</td>\n",
              "      <td>-SL {Thank you for your service! Up to 60% off...</td>\n",
              "      <td>{Save big on Samsung Galaxy Books and Tablets...</td>\n",
              "      <td>{Military members with Employee Pricing Progra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>military</td>\n",
              "      <td>2</td>\n",
              "      <td>-SL {Military Exclusive: Save up to 80% on Sam...</td>\n",
              "      <td>{Exclusive savings for Military members with ...</td>\n",
              "      <td>{Military members with Employee Pricing Progra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>military</td>\n",
              "      <td>3</td>\n",
              "      <td>-SL {Calling all Military Members: Employee Pr...</td>\n",
              "      <td>{Military members with Employee Pricing Progr...</td>\n",
              "      <td>{Military members with Employee Pricing Progra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>military</td>\n",
              "      <td>4</td>\n",
              "      <td>-SL {Thank you for your service! Limited-time ...</td>\n",
              "      <td>{Don't miss out, Military members with Employ...</td>\n",
              "      <td>{Military members with Employee Pricing Progra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>military</td>\n",
              "      <td>5</td>\n",
              "      <td>-SL {Military Appreciation Sale: Save up to 80...</td>\n",
              "      <td>{Military Appreciation Sale, save up to 80% o...</td>\n",
              "      <td>{Military members with Employee Pricing Progra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>military</td>\n",
              "      <td>6</td>\n",
              "      <td>-SL {Exclusive for Military: Employee Pricing ...</td>\n",
              "      <td>{Exclusive offer for Military members with Em...</td>\n",
              "      <td>{Military members with Employee Pricing Progra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>military</td>\n",
              "      <td>7</td>\n",
              "      <td>-SL {Thank you for your service! Don't miss ou...</td>\n",
              "      <td>{Time is running out, Military members with E...</td>\n",
              "      <td>{Military members with Employee Pricing Progra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>military</td>\n",
              "      <td>8</td>\n",
              "      <td>-SL {Military Members: Save up to 80% on Samsu...</td>\n",
              "      <td>{Military members with Employee Pricing Progr...</td>\n",
              "      <td>{Military members with Employee Pricing Progra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>military</td>\n",
              "      <td>9</td>\n",
              "      <td>-SL {Calling all Military Members: Employee Pr...</td>\n",
              "      <td>{Calling all Military members with Employee P...</td>\n",
              "      <td>{Military members with Employee Pricing Progra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>military</td>\n",
              "      <td>10</td>\n",
              "      <td>--SL {Thank you for your service! Limited-time...</td>\n",
              "      <td>{Military members with Employee Pricing Progr...</td>\n",
              "      <td>{Military members with Employee Pricing Progra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>military</td>\n",
              "      <td>11</td>\n",
              "      <td>--SL {Military Appreciation Sale: Save up to 8...</td>\n",
              "      <td>{Military Appreciation Sale, save up to 80% o...</td>\n",
              "      <td>{Military members with Employee Pricing Progra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>military</td>\n",
              "      <td>12</td>\n",
              "      <td>--SL {Exclusive for Military: Employee Pricing...</td>\n",
              "      <td>{Exclusive offer for Military members with Em...</td>\n",
              "      <td>{Military members with Employee Pricing Progra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>military</td>\n",
              "      <td>13</td>\n",
              "      <td>--SL {Thank you for your service! Don't miss o...</td>\n",
              "      <td>{Time is running out, Military members with E...</td>\n",
              "      <td>{Military members with Employee Pricing Progra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>military</td>\n",
              "      <td>14</td>\n",
              "      <td>--SL {Military Members: Save up to 80% on Sams...</td>\n",
              "      <td>{Military members with Employee Pricing Progr...</td>\n",
              "      <td>{Military members with Employee Pricing Progra...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-531caf63-190b-4cba-b735-efa20e599b4f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-531caf63-190b-4cba-b735-efa20e599b4f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-531caf63-190b-4cba-b735-efa20e599b4f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-78bc7f00-687a-431a-9c7c-1f440d13a642\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78bc7f00-687a-431a-9c7c-1f440d13a642')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-78bc7f00-687a-431a-9c7c-1f440d13a642 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7c5fd210-1045-488b-ad2f-e3d973b3f617\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7c5fd210-1045-488b-ad2f-e3d973b3f617 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 27,\n  \"fields\": [\n    {\n      \"column\": \"segment_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"military\",\n          \"Students\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"version\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 14,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          10,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"-SL {Back to School Sales Event: Save up to 60% on Samsung Galaxy Books and Tablets}\",\n          \"-SL {Military Appreciation Sale: Save up to 80% on Samsung Galaxy Books and Tablets}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PH\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \" {Get ready for school with the latest tech at unbeatable prices!} \",\n          \" {Exclusive savings for Military members with Employee Pricing Program Accounts, up to 80% off Samsung Galaxy Books and Tablets} \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"{Get ready for school with the latest Samsung Galaxy Books and Tablets! With up to 60% off, you can get the perfect device for your studies at an unbeatable price. Our Galaxy Books and Tablets are packed with features that will help you succeed in school, including long-lasting batteries, powerful processors, and brilliant displays. Plus, with our exclusive student pricing, you can save even more. Don't miss out on this incredible offer! Shop now and get ready for school with the latest tech at unbeatable prices!\",\n          \"{Get an additional 20% off on top of our already low prices on Samsung Galaxy Books and Tablets! This is your chance to save big on the latest tech for school. Our Galaxy Books and Tablets are packed with features that will help you succeed in school, including long-lasting batteries, powerful processors, and brilliant displays. Plus, with our exclusive student pricing, you can save even more. Don't miss out on this incredible offer! Shop now and get the latest tech for school at unbeatable prices!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 532
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "60NwaiGeWinB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}